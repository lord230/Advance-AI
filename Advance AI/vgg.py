# -*- coding: utf-8 -*-
"""VGG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MPevokkoLJUcrHNttZ-o7n5V1d8VcSYc
"""

import urllib.request

url = 'https://www.kaggle.com/api/v1/datasets/download/tongpython/cat-and-dog'
output_path = 'archive.zip'

urllib.request.urlretrieve(url, output_path)



import zipfile
from pathlib import Path

data_path = Path("data/")
img_path = data_path  / "cat_dog"

if img_path.exists():
    print(f"{img_path} already exists")
else:
    print(f"Creating {img_path}")
    img_path.mkdir(parents=True, exist_ok=True)

with zipfile.ZipFile("data/archive.zip", "r") as zip_ref:
  print("Extracting files...")
  zip_ref.extractall(img_path)
  print("Extacted")

data_path = Path("data/")
img_path = data_path  / "cat_dog"

import torch
from torch import nn
import matplotlib.pyplot as plt
from pathlib import Path

device = "cuda" if torch.cuda.is_available() else "cpu"
device

import os
def walk_through_dir(dir_path):
    for dirpath, dirnames, filenames in os.walk(dir_path):
        print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")

walk_through_dir(data_path)

train_dir = img_path / "training_set" / "training_set"
test_dir = img_path / "test_set" / "test_set"

train_dir,test_dir

train_dir.is_dir()

img_path

import random
from PIL import Image
import matplotlib.pyplot as plt
# /content/data/cat_dog/test_set/test_set/cats/cat.4001.jpg
random.seed(42)
image_path_list = list(img_path.glob("**/*.jpg"))


image_path_list

import random
from PIL import Image
import matplotlib.pyplot as plt
from pathlib import Path


img_path = Path("data/cat_dog")  # Assuming this is the correct path
image_path_list = list(img_path.glob("**/*.[Jj][Pp][Gg]")) # case-insensitive

print(image_path_list) # Check if the list is still empty

image_path_list

rand =(random.choice(image_path_list))

img = Image.open(rand)
img_class = rand.parent.stem
print(img_class)
print(rand)
print(img.height)
print(img.width)
img

import numpy as np
import matplotlib.pyplot as plt
img_arr = np.asarray(img)
# img_arr = int(img_arr)
plt.figure(figsize = (10,7))
plt.imshow(img_arr)
plt.show()

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

data_transform = transforms.Compose([
    transforms.Resize(size=(64,64)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ToTensor()
])

data_transform(img).permute(1,2,0).shape

from torchvision import datasets

train_data = datasets.ImageFolder(
    root = train_dir,
    transform = data_transform,
    target_transform = None
)

test_data = datasets.ImageFolder(
    root = test_dir,
    transform = data_transform,
)

len(train_data), len(test_data)

plt.figure(figsize=(10,7))
plt.imshow(train_data[0][0].permute(1,2,0))
plt.title(train_data[0][1])
plt.show()

from torch.utils.data import DataLoader
BATCH_SIZE = 32
train_dataloader = DataLoader(
    dataset = train_data,
    batch_size = BATCH_SIZE,
    shuffle = True,
    num_workers = os.cpu_count(),
    pin_memory = True
)
test_dataloader = DataLoader(
    dataset = test_data,
    batch_size = BATCH_SIZE,
    shuffle = False,
    num_workers = os.cpu_count(),
    pin_memory = True
)

simple_transform = transforms.Compose([
    transforms.Resize(size=(64,64)),
    transforms.ToTensor()
])

from torchvision import datasets

train_data_simple = datasets.ImageFolder(
    root = train_dir,
    transform = simple_transform,
    target_transform = None
)

test_data_simple = datasets.ImageFolder(
    root = test_dir,
    transform = simple_transform,
)

len(train_data_simple) , len(test_data_simple)

5

from torch.utils.data import DataLoader
BATCH_SIZE = 5
train_dataloadder_simple = DataLoader(
    dataset = train_data_simple,
    batch_size = BATCH_SIZE,
    shuffle = True,
    num_workers = os.cpu_count(),
)
test_dataloadder_simple = DataLoader(
    dataset = test_data_simple,
    batch_size = BATCH_SIZE,
    shuffle = False,
    num_workers = os.cpu_count(),
)

len(train_dataloadder_simple), len(test_dataloadder_simple)

class simple(nn.Module):
  def __init__(self, input:int, hidden:int, output:int):
    super().__init__ ()
    self.conv_bloc_1 = nn.Sequential(
        nn.Conv2d(in_channels= input,
                  out_channels = hidden,
                  kernel_size = 3,
                  stride= 1,
                  padding = 0),
        nn.ReLU(),
        nn.Conv2d(in_channels= hidden,
                  out_channels = hidden,
                  kernel_size = 3,
                  stride= 1,
                  padding = 0),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size = 2,
                     stride = 2)
    )
    self.conv_bloc_2 = nn.Sequential(
        nn.Conv2d(in_channels= hidden,
                  out_channels = hidden,
                  kernel_size = 3,
                  stride= 1,
                  padding = 0),
        nn.ReLU(),
        nn.Conv2d(in_channels= hidden,
                  out_channels = hidden,
                  kernel_size = 3,
                  stride= 1,
                  padding = 0),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size = 2,
                     stride = 2)
    )
    self.classifier = nn.Sequential(
        nn.Flatten(),
        nn.Linear(in_features = hidden*13*13,
                  out_features = output)
    )

  def forward(self,x):
      # print(x.shape)
      x = self.conv_bloc_1(x)
      # plt.imshow(x[0, 0].detach().permute(1,2,0).cpu().numpy()) # The error was here
      # # Since x[0, 0] is 2-dimensional, we can just display it directly
      # plt.imshow(x[0,0].detach().cpu().numpy(), cmap='gray') # Add cmap='gray' for grayscale display
      # plt.show()
      # print(x.shape)
      x = self.conv_bloc_2(x)
      # print(x.shape)
      # Similar change for the second convolutional block output
      # plt.imshow(x[0,0].detach().cpu().numpy(), cmap='gray') # Add cmap='gray' for grayscale display
      # plt.show()
      x = self.classifier(x)
      # print(x.shape)
      return x

torch.manual_seed(42)
model_simple = simple(3,20,2).to(device)
model_simple

image_batch , label_batch = next(iter(train_dataloadder_simple))
 image_batch.shape, label_batch.shape

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(params = model_simple.parameters(),
                             lr = 0.0001)



def train_step(model: torch.nn.Module,
               dataloader: torch.utils.data.DataLoader,
               loss_fn: torch.nn.Module,
               optimizer: torch.optim.Optimizer,
               scheduler: torch.optim.lr_scheduler.StepLR,
               device = device):
  model.train()
  train_loss, train_acc = 0,0

  for batch, (X,y) in enumerate(dataloader):
    X,y = X.to(device), y.to(device)
    y_pred = model(X)
    loss = loss_fn(y_pred,y)
    train_loss += loss.item()

    optimizer.zero_grad()
    loss.backward()

    optimizer.step()
    y_pred_class = torch.argmax(torch.softmax(y_pred, dim = 1), dim = 1)
    train_acc += (y_pred_class == y).sum().item()/len(y_pred)
  scheduler.step()
  train_loss = train_loss / len(dataloader)
  train_acc = train_acc / len(dataloader)
  return train_loss, train_acc

def test_loop(model: torch.nn.Module,
              dataloader: torch.utils.data.DataLoader,
              loss_fn : torch.nn.Module,
              device = device):
  model.eval()
  test_loss, test_acc = 0,0
  with torch.inference_mode():
    for batch , (X,y) in enumerate(dataloader):
      X,y = X.to(device), y.to(device)

      test_pred_logits = model(X)
      loss = loss_fn(test_pred_logits, y)
      test_loss += loss.item()

      test_pred_labels = test_pred_logits.argmax(dim = 1)
      test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))
    test_loss = test_loss / len(dataloader)
    test_acc = test_acc / len(dataloader)
  # Add a return statement to return test_loss and test_acc
  return test_loss, test_acc

from tqdm import tqdm
epochs = 2
train_losses = []
test_losses = []
train_accuracy = []
test_accuracy = []
scheduler = torch.optim.lr_scheduler.StepLR(optimizer , step_size = 10, gamma = 0.1)
for epoch in tqdm(range(epochs)):
  train_loss, train_acc = train_step(model = model_simple,
                                      dataloader = train_dataloadder_simple,
                                      loss_fn = loss_fn,
                                      optimizer = optimizer,
                                      scheduler = scheduler
                                      )
  test_loss, test_acc = test_loop(model = model_simple,
                                  dataloader = test_dataloadder_simple,
                                  loss_fn = loss_fn)

  train_losses.append(train_loss)
  test_losses.append(test_loss)
  train_accuracy.append(train_acc)
  test_accuracy.append(test_acc)
  print(f"\n Epoch: {epoch+1} | Train_loss: {train_loss} | Train_acc: {train_acc} | Test_loss: {test_loss} | Test_acc: {test_acc}")

import matplotlib.pyplot as plt

# Assuming you have these lists: train_losses, test_losses, train_accuracy, test_accuracy

plt.figure(figsize=(10, 6))  # Adjust figure size for better visibility

# Plot lines with labels and distinct colors
plt.plot(test_losses, label='Test Loss', color='red', linestyle='--')
plt.plot(test_accuracy, label='Test Accuracy', color='blue', linestyle='-')
plt.plot(train_losses, label='Train Loss', color='orange', linestyle='--')
plt.plot(train_accuracy, label='Train Accuracy', color='green', linestyle='-')

plt.title('Training and Test Metrics', fontsize=16)  # Increase title font size
plt.xlabel('Epoch', fontsize=12)  # Increase label font size
plt.ylabel('Value', fontsize=12)  # Increase label font size

plt.legend(fontsize=10)  # Add a legend with adjusted font size
plt.grid(True)  # Add a grid for better readability

plt.tight_layout()  # Adjust layout to prevent overlapping elements
plt.show()

#overfitting

with torch.inference_mode():
  for i in range(len(test_data_simple)):
    image, label = test_data_simple[i][0], test_data_simple[i][1]
    pred = model_simple((image_batch).to(device))
pred

for i in range(len(pred)):
  print(f"Predicted: {pred[i].argmax()}, Actual: {label_batch[i]}")

# COMPLEX DATA AUGMENTATION

from torchvision import transforms

data_aug = transforms.Compose([
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=30),
    transforms.RandomResizedCrop(size=(64,64)),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.RandomGrayscale(p=0.1),
    transforms.ToTensor()
])

train_data_aug = datasets.ImageFolder(
    root = train_dir,
    transform = data_aug,
    target_transform = None
)
test_data_aug = datasets.ImageFolder(
    root = test_dir,
    transform = data_aug,
)

train_dataloader_aug = DataLoader(
    dataset = train_data_aug,
    batch_size = BATCH_SIZE,
    shuffle = True,
    num_workers = os.cpu_count(),
)
test_dataloader_aug = DataLoader(
    dataset = test_data_aug,
    batch_size = BATCH_SIZE,
    shuffle = False,
    num_workers = os.cpu_count(),
)


# Mid Level Data Augmentation 

data_aug_mid = transforms.Compose([
    transforms.RandomVirticalFlip(p=0.5),
    transforms.functional.rgb_to_grayscale(num_output_channels = 1),
    transforms.Resize(size=(64,64)),
    transforms.ToTensor()
])

train_data_aug_simple = datasets.ImageFolder(
    root = train_dir,
    transform = data_aug_mid,
    target_transform = None
)

test_data_aug_simple = datasets.ImageFolder(
    root = test_dir,
    transform = data_aug_mid
)

train_dataloader_mid = DataLoader(
    dataset = train_dataloadder_simple,
    batch_size = BATCH_SIZE,
    shuffle = True,
    num_workers = os.cpu_count(),
)

test_dataloader_mid = DataLoader(
    dataset = test_data_aug_simple,
    batch_size = BATCH_SIZE,
    num_workers = os.cpu_count(),
)



len(train_dataloader_aug), len(test_dataloader_aug)

class simple(nn.Module):
  def __init__(self, input:int, hidden:int, output:int):
    super().__init__ ()
    self.conv_bloc_1 = nn.Sequential(
        nn.Conv2d(in_channels= input,
                  out_channels = hidden,
                  kernel_size = 3,
                  stride= 1,
                  padding = 0),
        nn.ReLU(),
        nn.Conv2d(in_channels= hidden,
                  out_channels = hidden,
                  kernel_size = 3,
                  stride= 1,
                  padding = 0),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size = 2,
                     stride = 2)
    )
    self.conv_bloc_2 = nn.Sequential(
        nn.Conv2d(in_channels= hidden,
                  out_channels = hidden,
                  kernel_size = 3,
                  stride= 1,
                  padding = 0),
        nn.ReLU(),
        nn.Conv2d(in_channels= hidden,
                  out_channels = hidden,
                  kernel_size = 3,
                  stride= 1,
                  padding = 0),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size = 2,
                     stride = 2)
    )
    self.classifier = nn.Sequential(
        nn.Flatten(),
        nn.Linear(in_features = hidden*13*13,
                  out_features = output)
    )

  def forward(self,x):
      return self.classifier(self.conv_bloc_2(self.conv_bloc_1(x)))


class complex_VGG(nn.Module):
    def __init__ (self,
    input : int,
    hidden : int,
    output: int):
      super().__init__ ()
      self.block_1 = nn.Sequential(
        nn.Conv2d(in_channels = input,
                  out_channels = hidden,
                  kernal_size = 3,
                  sride = 1,
                  padding = 0
        ),
        nn.Tanh(),
        nn.Conv2d(in_channels = hidden,
                  out_channels = hidden,
                  kernal_size = 3,
                  stride = 1,
                  padding = 0),
        nn.Tanh(),
        nn.MaxPool2d(kernal_size = 2,
                     stride = 2)
        ),
      self.block_2 = nn.Sequential(
        nn.Conv2d(in_channels = hidden,
                     out_channels = hidden,
                     kernal_size = 3,
                     stride = 1,
                     padding = 0),
        nn.Tanh(),
        nn.Conv2d(in_channels = hidden,
                     out_channels = hidden,
                     kernal_size = 3,
                     stride = 1,
                     padding = 0)
        nn.Tanh(),
        nn.MaxPool2d(kernal_size = 2,stride = 2)
      ),
      self.classifier = nn.Sequential(
        nn.Flatten(),
        nn.Linear(in_features = hidden, out_features = output)
      )

    def forward(self,x):
        return self.classifier(self.block_2(self.block_1(x)))

class VGG_Aug(nn.Module):
   def __init__ (self, input :int,
                 hidden: int,
                 output: int):
      super().__init__()
      self.block_1 = nn.Sequential(
         nn.Conv2d(
            in_channels = input,
            out_channels = hidden,
            kernal_size = 3,
            stride = 1,
            padding = 0
         )
         nn.Tanh(),
         nn.Conv2d(
            in_channels = hidden,
            out_channels = hidden,
            kernal = 3,
            stride = 1,
            padding = 0
         )
         nn.Tanh(),
         nn.Conv2d(
            in_channels = hidden,
            out_channels = hidden,
            kernal = 3,
            stride = 1,
            padding = 0
         )
         nn.Tanh(),
         nn.MaxPool(hidden,hidden)
      ),
      self.block_2 = nn.Sequential(
         nn.Conv2d(
           in_channels =  hidden,
            out_channels = hidden,
            kernal = 3,
            stride = 1,
            padding = 0,
         )
         nn.Tanh(),
         nn.Conv2d(
            in_channels =  hidden,
            out_channels = hidden,
            kernal = 3,
            stride = 1,
            padding = 0,
         )
         nn.Tanh(),
         nn.Conv2d(
           in_channels =  hidden,
            out_channels = hidden,
            kernal = 3,
            stride = 1,
            padding = 0,
         )
         nn.Tanh()
         nn.MaxPool(hidden,hidden)
      )
      self.block_3 = nn.Sequential(
         nn.Conv2d(
            in_channels = hidden,
            out_channels = hidden,
            kernal = 3,
            stride = 1,
            padding = 0,
         )
         nn.Tanh(),
         nn.Conv2d(
            in_channels = hidden,
            out_channels = hidden,
            kernal = 3,
            stride = 1,
            padding = 0,
         )
         nn.Tanh(),
         nn.Conv2d(
            in_channels = hidden,
            out_channes = hidden,
            kernal = 3,
            stride = 1,
            padding = 0,
         )
         nn.Tanh(),
         nn.Conv2d(
            in_channels = hidden,
            out_channels = hidden,
            kernal = 3,
            stride = 1,
            padding = 0,
         )
         nn.Tanh(),
         nn.Conv2d(
            in_channels = hidden,
            out_channels = hidden,
            kernal = 3,
            stride = 1,
            padding = 0,
         )
      )
      self.block_4 = nn.Sequential(
         nn.Conv2d(
            in_features = hidden,
            out_features = hidden,
            kernal = 3,
            stride = 1,
            padding = 0,
         )
         nn.Tanh();
         nn.Conv2d(
            in_features = hidden,
            out_features = hidden,
            kernal = 3,
            stride = 1,
            padding = 0,
         )
         nn.Tanh(),
         nn.Conv2d(
            in_features = hidden,
            out_features = hidden,
            kernal = 3,
            stride = 1,
            padding = 0,
         )
         nn.Tanh(),
         nn.Conv2d(
            in_features = hidden,
            out_features = hidden,
            kernal = 3,
            stride = 1,
            padding = 0,
         )
         nn.Tanh(),
         nn.Conv2d(
            in_features = hidden,
            out_features = hidden,
            kernal = 3,
            stride = 1,
            padding = 0,
         )
      )
      self.classifier = nn.Sequential(
         nn.Flatten(),
         nn.Linear(in_channels = hidden, out_channels = output)
      )

   def forward(self,x):
      return self.classifier(self.block_3(self.block_2(self.block_1(x))))

       
torch.manual_seed(42)
model_renet = VGG_Aug(3,1024,2)


loss_resnet = nn.CrossEntropyLoss()
optimizer_resenet = torch.optim.Adam(model_renet.parameter(),lr = 0.001)



torch.manual_seed(42)
model_aug = simple(3,20,2).to(device)
model_simple

model_mid = complex_VGG(3,20,2).to(device)
model_mid

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model_aug.parameters(), lr = 0.0001)

loss_fn_1 = nn.CrossEntropyLoss()
optimizer_1 = torch.optim.Admam(model_mid.parameters(),lr = 0.001)

torch.manual_seed(42)



epochs = 20 
train_losses = []
train_accy = []
test_losses = []
test_accy = []

for epoch in tqdm(range(epochs)):
    train_loss , train_acc = train_step(model = model_mid,
    dataloader = train_data_aug_simple,
    loss_fn=loss_fn_1,
    optimizer = optimizer_1)

    test_loss , test_acc = test_loop(model=model_mid,
    dataloader= test_data_aug_simple,
    loss_fn= loss_fn_1)

    train_losses.append(train_loss)
    train_accy.append(train_acc)
    test_losses.append(test_loss)
    test_accy.append(test_acc)
    print(f"test loss `{test_loss}` | test accuracy `{test_acc}` | train loss `{train_loss}` | train acc `{train_acc}`")






torch.manual_seed(42)

from tqdm import tqdm
epochs = 20
train_losses = []
test_losses = []
train_accuracy = []
test_accuracy = []

for epoch in tqdm(range(epochs)):
  train_loss, train_acc = train_step(model = model_aug,
                                      dataloader = train_dataloader_aug,
                                      loss_fn = loss_fn,
                                      optimizer = optimizer,
                                      scheduler = scheduler
                                      )
  test_loss, test_acc = test_loop(model = model_aug,
                                  dataloader = test_dataloader_aug,
                                  loss_fn = loss_fn)
  train_losses.append(train_loss)
  test_losses.append(test_loss)
  train_accuracy.append(train_acc)
  test_accuracy.append(test_acc)
  print(f"\n Epoch: {epoch+1} | Train_loss: {train_loss} | Train_acc: {train_acc} | Test_loss: {test_loss} | Test_acc: {test_acc}")

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))

plt.plot(test_losses, label='Test Loss', color='red', linestyle='--')
plt.plot(test_accuracy, label='Test Accuracy', color='blue', linestyle='-')
plt.plot(train_losses, label='Train Loss', color='orange', linestyle='--')
plt.plot(train_accuracy, label='Train Accuracy', color='green', linestyle='-')

plt.title('Training and Test Metrics', fontsize=16)
plt.xlabel('Epoch', fontsize=12)
plt.ylabel('Value', fontsize=12)

plt.legend(fontsize=10)
plt.grid(True)

plt.tight_layout()
plt.show()